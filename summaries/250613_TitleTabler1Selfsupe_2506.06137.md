**一句话概要**  
Table-r1通过自监督布局转换推理与混合范式强化学习，显著提升了小型语言模型在基于程序的表格推理任务中的性能，使其在多项基准测试中达到与大型模型竞争的水平。

**主体**  
表格推理任务要求模型对半结构化表格数据进行复杂逻辑推演，这对参数量有限的小型语言模型（如LLaMA-8B）尤为困难。传统文本式推理（T-TR）在数值计算等场景存在明显缺陷，而基于程序生成的推理（P-TR）虽能通过执行代码提升准确性，却面临两大挑战：模型对多样化表格布局的泛化能力不足，以及受限于代码生成能力导致的推理不一致性。

作者提出的Table-r1采用两阶段框架破解这一难题。第一阶段设计自监督布局转换推理任务，通过程序化视角重构表格布局（如行列转置、键值重组），使模型从原始数据中学习到与布局无关的通用表征。第二阶段创新性地融合强化学习与动态回退机制：改进版Group Relative Policy Optimization优化程序生成策略的同时，允许模型在代码生成置信度不足时自动切换至文本推理模式，形成混合推理范式。这种设计既保障了数值场景的程序化精确性，又保留了文本推理的灵活性。

在四个主流表格推理基准测试中，Table-r1将LLaMA-8B的基础准确率平均提升15%以上，最高单项提升达21.3%。尤其值得注意的是，其程序生成成功率较基线提高3.2倍，且在数值推理任务中首次使小型模型达到与GPT-4o相当的水平。可视化分析显示，经过布局转换预训练的模型对表格结构变化的鲁棒性显著增强，错误案例多集中于语义歧义而非布局适应问题。

**最后一句**  
这项研究为资源受限场景下的结构化推理提供了新范式，其混合推理框架与程序化表征学习方法对多模态数据处理具有普适启示。