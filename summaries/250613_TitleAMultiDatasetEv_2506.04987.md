**一句话概要**  
该研究系统评估了CodeBERT和CodeT5两种预训练模型在跨语言漏洞自动修复任务中的表现，揭示了模型在泛化能力和上下文适应性上的关键差异。

**主体**  
软件漏洞修复作为自动程序修复（APR）的安全关键环节，当前研究仍存在明显空白。尽管通用缺陷修复技术已取得进展，但针对漏洞修复这一特殊场景，现有方法在跨语言适应性和未知漏洞泛化能力上表现不足。作者指出，碎片化代码上下文和复杂漏洞模式是阻碍现有模型效果的两大核心挑战。

为解决上述问题，研究团队设计了多维度评估框架，在六个数据集和四种编程语言上对比CodeBERT与CodeT5的表现。实验发现两种模型展现出互补优势：CodeBERT在代码上下文不完整时表现出更强的鲁棒性，这得益于其双向注意力机制对局部语义的捕捉；而基于序列到序列架构的CodeT5则更擅长处理需要长距离依赖的复杂漏洞模式，其生成式架构还展现出更好的计算扩展性。值得注意的是，通过微调策略虽然能提升模型在已知漏洞分布上的修复准确率，但在面对全新漏洞类型时，两种模型的性能均出现显著下降。

**效果验证**  
跨数据集测试表明，CodeT5在C/C++漏洞修复任务中达到最高62.3%的准确率，比CodeBERT高出7.5个百分点；但在Python的碎片化代码场景下，CodeBERT以54.1%的准确率反超。可视化分析显示，模型失败案例多集中于需要跨函数分析的漏洞场景，这揭示了当前基于代码片段的训练范式存在根本局限。研究还发现，模型在Java和Go语言上的表现存在显著差异，说明编程语言特性会显著影响修复效果。

这项工作为安全敏感的自动修复系统开发提供了重要基准，其发现的模型泛化瓶颈将推动未来研究向全程序分析和多模态漏洞表征方向发展。