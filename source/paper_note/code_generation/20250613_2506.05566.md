# 250613_ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation

---
**论文信息**

- **标题**: ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation
- **arXiv ID**: 2506.05566
- **作者**: Authors:Chenhui Deng, Yun-Da Tsai, Guan-Ting Liu, Zhongzhi Yu, Haoxing Ren
- **发表日期**: 2025-06-05T20:24:58+00:00
- **论文链接**: [2506.05566](https://arxiv.org/abs/2506.05566)
- **总结生成时间**: 2025-06-13 15:03:02

---

**一句话概要**  
ScaleRTL通过构建高质量RTL推理数据集与测试时计算扩展策略，显著提升了大型语言模型在硬件描述语言生成任务中的性能。

**主体**  
当前大型语言模型在通用编程任务中已接近人类水平，但在寄存器传输级（RTL）代码生成领域仍面临关键挑战：高质量训练数据的稀缺性导致模型难以深入理解硬件设计逻辑。以往研究虽尝试对模型进行微调，但未能突破数据瓶颈，且缺乏测试时动态扩展推理能力，限制了生成代码的准确性和复杂性。

作者提出ScaleRTL框架，从数据和计算两个维度进行创新。首先构建了包含3.5B标记的大规模RTL推理数据集，其中每条数据平均包含56K标记的链式思维推理轨迹，覆盖丰富的硬件设计知识。基于该数据集微调通用推理模型后，进一步引入测试时计算扩展策略，使模型能够通过迭代式自我反思与修正机制动态优化推理过程。这种双重扩展机制使模型既能学习深层次RTL设计模式，又能实时调整生成策略。

实验验证表明，ScaleRTL在VerilogEval和RTLLM基准测试中分别以18.4%和12.7%的优势超越18个基线模型，其生成的RTL代码在功能正确性和结构合理性上均达到当前最优水平。可视化分析显示，模型的自我修正机制能有效捕捉时序逻辑错误等典型硬件设计缺陷。

**最后一句**  
该研究为领域专用代码生成提供了数据构建与动态推理协同优化的新范式，对加速硬件设计自动化具有重要启示意义。