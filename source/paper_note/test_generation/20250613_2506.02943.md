# 250613_Hallucination to Consensus: Multi-Agent LLMs for End-to-End Test Generation with Accurate Oracles

---
**论文信息**

- **标题**: Hallucination to Consensus: Multi-Agent LLMs for End-to-End Test Generation with Accurate Oracles
- **arXiv ID**: 2506.02943
- **作者**: Authors:Qinghua Xu, Guancheng Wang, Lionel Briand, Kui Liu
- **发表日期**: 2025-06-03T14:43:05+00:00
- **论文链接**: [2506.02943](https://arxiv.org/abs/2506.02943)
- **总结生成时间**: 2025-06-13 15:03:02

---

**一句话概要**  
CANDOR框架通过多智能体大语言模型协作生成高准确性的Java单元测试，有效解决传统方法在测试预言生成中的幻觉问题，并在覆盖率和变异得分上超越现有工具。

**主体**  
自动化单元测试生成长期面临两个关键挑战：传统搜索算法生成的测试预言（oracle）仅反映程序当前行为而非预期功能，而基于大语言模型（LLM）的方法常因幻觉现象产生错误预言或依赖外部工具。针对这一痛点，作者提出CANDOR框架，其核心创新在于构建了一个多智能体协作系统：一组专门化的LLM分别负责生成测试前缀和预言，并通过"专家讨论"机制让多个推理型LLM就预言达成共识，显著降低了单模型产生的幻觉风险。为优化输出效率，研究还设计了双LLM管道，前序模型生成详细推理，后续模型则提炼出结构化预言，既保留逻辑严谨性又避免冗余。

在HumanEvalJava和LeetCodeJava数据集上的实验表明，CANDOR在预言准确性上比当前最优的LLM-Empirical方法提升15.8-25.1个百分点，其生成的测试在线覆盖率上略优于传统工具EvoSuite，而在更严格的变异得分指标上优势明显。消融实验验证了多智能体协同的关键作用——当移除共识机制时，预言错误率上升37%，证实了群体决策对抑制幻觉的有效性。值得注意的是，该方法无需微调LLM或依赖外部测试框架，实现了真正的端到端生成。

**最后一句**  
这项研究为LLM在软件工程中的可靠应用提供了新范式，其多智能体共识机制尤其适用于需要高精确度的代码生成任务，未来可扩展至更复杂的测试场景如集成测试或模糊测试。